{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffb76d9",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 1: Import th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "\n",
    "ƒê·∫ßu ti√™n, ch√∫ng ta c·∫ßn import c√°c th∆∞ vi·ªán. M√¨nh s·∫Ω gi·∫£i th√≠ch t·ª´ng c√°i nh√©!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3ba767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Import th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "# Th∆∞ vi·ªán c∆° b·∫£n\n",
    "import pandas as pd\n",
    "import numpy as np   # T√≠nh to√°n s·ªë h·ªçc\n",
    "import matplotlib.pyplot as plt  # V·∫Ω bi·ªÉu ƒë·ªì\n",
    "import seaborn as sns\n",
    "\n",
    "# Th∆∞ vi·ªán Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier  # Model Random Forest\n",
    "from sklearn.model_selection import train_test_split  # Chia train/test\n",
    "\n",
    "# T·∫Øt warning ƒë·ªÉ m√†n h√¨nh s·∫°ch s·∫Ω h∆°n\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Import th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20108233",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 2: Load d·ªØ li·ªáu Titanic\n",
    "\n",
    "Gi·ªù ch√∫ng ta s·∫Ω t·∫£i d·ªØ li·ªáu Titanic. Dataset n√†y c√≥ s·∫µn trong th∆∞ vi·ªán seaborn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71af2d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset c√≥ 891 h√†ng v√† 15 c·ªôt\n",
      "\n",
      "üîç 5 d√≤ng ƒë·∫ßu ti√™n:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load d·ªØ li·ªáu Titanic t·ª´ seaborn\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(f\"üìä Dataset c√≥ {df.shape[0]} h√†ng v√† {df.shape[1]} c·ªôt\")\n",
    "print(\"\\nüîç 5 d√≤ng ƒë·∫ßu ti√™n:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df32db7",
   "metadata": {},
   "source": [
    "### Gi·∫£i th√≠ch c√°c c·ªôt quan tr·ªçng:\n",
    "- **survived**: 1 = s·ªëng s√≥t, 0 = t·ª≠ n·∫°n (ƒë√¢y l√† target ch√∫ng ta c·∫ßn d·ª± ƒëo√°n)\n",
    "- **pclass**: H·∫°ng v√© (1, 2, 3)\n",
    "- **sex**: Gi·ªõi t√≠nh\n",
    "- **age**: Tu·ªïi\n",
    "- **fare**: Gi√° v√©\n",
    "- **embarked**: C·∫£ng xu·∫•t ph√°t (C, Q, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22689f50",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 3: Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "\n",
    "Tr∆∞·ªõc khi train model, ch√∫ng ta c·∫ßn:\n",
    "1. Ch·ªçn features (ƒë·∫∑c tr∆∞ng) ƒë·ªÉ d√πng\n",
    "2. X·ª≠ l√Ω missing values (gi√° tr·ªã b·ªã thi·∫øu)\n",
    "3. Convert text sang s·ªë (v√¨ ML ch·ªâ hi·ªÉu s·ªë!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9ff7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç S·ªë gi√° tr·ªã b·ªã thi·∫øu m·ªói c·ªôt:\n",
      "survived      0\n",
      "pclass        0\n",
      "sex           0\n",
      "age         177\n",
      "fare          0\n",
      "embarked      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ch·ªçn c√°c features ƒë∆°n gi·∫£n\n",
    "df_clean = df[['survived', 'pclass', 'sex', 'age', 'fare', 'embarked']].copy()\n",
    "\n",
    "# Xem c√≥ bao nhi√™u gi√° tr·ªã b·ªã thi·∫øu\n",
    "print(\"üîç S·ªë gi√° tr·ªã b·ªã thi·∫øu m·ªói c·ªôt:\")\n",
    "print(df_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "076410cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ X·ª≠ l√Ω xong! Ki·ªÉm tra l·∫°i:\n",
      "survived    0\n",
      "pclass      0\n",
      "sex         0\n",
      "age         0\n",
      "fare        0\n",
      "embarked    0\n",
      "dtype: int64\n",
      "\n",
      "üìä D·ªØ li·ªáu sau khi x·ª≠ l√Ω:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  sex   age     fare  embarked\n",
       "0         0       3    0  22.0   7.2500         0\n",
       "1         1       1    1  38.0  71.2833         1\n",
       "2         1       3    1  26.0   7.9250         0\n",
       "3         1       1    1  35.0  53.1000         0\n",
       "4         0       3    0  35.0   8.0500         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X·ª≠ l√Ω missing values ƒë∆°n gi·∫£n\n",
    "df_clean['age'].fillna(df_clean['age'].median(), inplace=True)  # ƒêi·ªÅn tu·ªïi = median\n",
    "df_clean['fare'].fillna(df_clean['fare'].median(), inplace=True)  # ƒêi·ªÅn gi√° v√© = median\n",
    "df_clean['embarked'].fillna('S', inplace=True)  # ƒêi·ªÅn c·∫£ng ph·ªï bi·∫øn nh·∫•t\n",
    "\n",
    "# Convert text sang s·ªë\n",
    "df_clean['sex'] = df_clean['sex'].map({'male': 0, 'female': 1})  # male=0, female=1\n",
    "df_clean['embarked'] = df_clean['embarked'].map({'S': 0, 'C': 1, 'Q': 2})  # S=0, C=1, Q=2\n",
    "\n",
    "print(\"‚úÖ X·ª≠ l√Ω xong! Ki·ªÉm tra l·∫°i:\")\n",
    "print(df_clean.isnull().sum())\n",
    "print(\"\\nüìä D·ªØ li·ªáu sau khi x·ª≠ l√Ω:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d1a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ X shape: (891, 5)\n",
      "‚úÖ y shape: (891,)\n"
     ]
    }
   ],
   "source": [
    "# T√°ch X (features) v√† y (target)\n",
    "X = df_clean.drop('survived', axis=1)  # X = t·∫•t c·∫£ c·ªôt tr·ª´ 'survived'\n",
    "y = df_clean['survived']  # y = c·ªôt 'survived'\n",
    "\n",
    "print(f\"‚úÖ X shape: {X.shape}\")\n",
    "print(f\"‚úÖ y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a96ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia train/test (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üìö Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"üìù Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e6173",
   "metadata": {},
   "source": [
    "---\n",
    "# B√†i 1: So s√°nh Grid Search vs Random Search\n",
    "\n",
    "## V·∫•n ƒë·ªÅ: \"L·ªùi nguy·ªÅn s·ªë chi·ªÅu\" l√† g√¨?\n",
    "\n",
    "Khi ch√∫ng ta c√≥ **nhi·ªÅu hyperparameter** c·∫ßn tune, s·ªë l∆∞·ª£ng t·ªï h·ª£p tƒÉng **C·ª∞C NHANH**!\n",
    "\n",
    "V√≠ d·ª•:\n",
    "- 3 tham s·ªë, m·ªói c√°i 10 gi√° tr·ªã ‚Üí 10 √ó 10 √ó 10 = **1,000 t·ªï h·ª£p**\n",
    "- 5 tham s·ªë, m·ªói c√°i 10 gi√° tr·ªã ‚Üí 10^5 = **100,000 t·ªï h·ª£p**\n",
    "- 10 tham s·ªë, m·ªói c√°i 10 gi√° tr·ªã ‚Üí 10^10 = **10 t·ª∑ t·ªï h·ª£p** üò±\n",
    "\n",
    "‚Üí ƒê√¢y g·ªçi l√† **\"Curse of Dimensionality\"** (L·ªùi nguy·ªÅn s·ªë chi·ªÅu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a091c1c7",
   "metadata": {},
   "source": [
    "## Ph·∫ßn A: T√≠nh s·ªë t·ªï h·ª£p Grid Search\n",
    "\n",
    "Gi·ªù m√¨nh s·∫Ω ƒë·ªãnh nghƒ©a m·ªôt kh√¥ng gian hyperparameter v√† t√≠nh xem ph·∫£i th·ª≠ bao nhi√™u t·ªï h·ª£p!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85325800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªãnh nghƒ©a kh√¥ng gian hyperparameter\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],        # S·ªë c√¢y trong r·ª´ng\n",
    "    'max_depth': [5, 10, 15, 20],          # ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y\n",
    "    'min_samples_split': [2, 5, 10],       # S·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ split node\n",
    "    'min_samples_leaf': [1, 2, 4],         # S·ªë m·∫´u t·ªëi thi·ªÉu ·ªü l√°\n",
    "    'max_features': ['sqrt', 'log2']       # S·ªë features x√©t m·ªói split\n",
    "}\n",
    "\n",
    "print(\"üìù Kh√¥ng gian hyperparameter:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "total = 1\n",
    "for param, values in param_grid.items():\n",
    "    n = len(values)\n",
    "    print(f\"{param:20s}: {n} gi√° tr·ªã {values}\")\n",
    "    total *= n\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nüî¢ T·ªîNG S·ªê T·ªî H·ª¢P: {total}\")\n",
    "print(f\"\\n‚è∞ N·∫øu d√πng 5-fold Cross-Validation:\")\n",
    "print(f\"   ‚Üí Ph·∫£i train model: {total} √ó 5 = {total * 5} l·∫ßn!\")\n",
    "print(f\"   ‚Üí Gi·∫£ s·ª≠ 1 l·∫ßn train m·∫•t 2 gi√¢y\")\n",
    "print(f\"   ‚Üí T·ªïng th·ªùi gian: {total * 5 * 2 / 60:.1f} ph√∫t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9252aee",
   "metadata": {},
   "source": [
    "### üí° Gi·∫£i th√≠ch:\n",
    "\n",
    "- Grid Search ph·∫£i th·ª≠ **T·∫§T C·∫¢** c√°c t·ªï h·ª£p\n",
    "- 3 √ó 4 √ó 3 √ó 3 √ó 2 = **216 t·ªï h·ª£p**\n",
    "- V·ªõi 5-fold CV = **1,080 l·∫ßn training**!\n",
    "- ƒê√¢y m·ªõi ch·ªâ l√† 5 hyperparameters, trong th·ª±c t·∫ø c√≥ th·ªÉ c√≥ h∆°n 10!\n",
    "\n",
    "‚Üí **V·∫•n ƒë·ªÅ**: T·ªën c·ª±c k·ª≥ nhi·ªÅu th·ªùi gian! ‚è∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03276476",
   "metadata": {},
   "source": [
    "## Ph·∫ßn B: Random Search - Gi·∫£i ph√°p th√¥ng minh\n",
    "\n",
    "**√ù t∆∞·ªüng**: Thay v√¨ th·ª≠ T·∫§T C·∫¢, ch·ªâ th·ª≠ **NG·∫™U NHI√äN m·ªôt s·ªë t·ªï h·ª£p**!\n",
    "\n",
    "Nghe c√≥ v·∫ª ng·ªõ ng·∫©n nh∆∞ng th·ª±c t·∫ø **r·∫•t hi·ªáu qu·∫£**! üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003a787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# T·∫°o Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Ch·∫°y Random Search v·ªõi CH·ªà 30 l·∫ßn th·ª≠\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30,  # CH·ªà th·ª≠ 30 t·ªï h·ª£p ng·∫´u nhi√™n!\n",
    "    cv=5,       # 5-fold Cross-Validation\n",
    "    scoring='accuracy',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,  # D√πng t·∫•t c·∫£ CPU cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"üöÄ B·∫Øt ƒë·∫ßu Random Search...\\n\")\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"\\n‚úÖ Ho√†n th√†nh!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e25bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem k·∫øt qu·∫£\n",
    "print(\"=\"*60)\n",
    "print(\"üèÜ K·∫æT QU·∫¢ RANDOM SEARCH\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Best Score (CV Accuracy): {random_search.best_score_:.4f}\")\n",
    "print(f\"\\n‚öôÔ∏è  Best Hyperparameters:\")\n",
    "for param, value in random_search.best_params_.items():\n",
    "    print(f\"   {param:20s}: {value}\")\n",
    "\n",
    "# Test tr√™n test set\n",
    "test_score = random_search.score(X_test, y_test)\n",
    "print(f\"\\n‚ú® Test Accuracy: {test_score:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74e772",
   "metadata": {},
   "source": [
    "### üìä So s√°nh Grid Search vs Random Search:\n",
    "\n",
    "| Ph∆∞∆°ng ph√°p | S·ªë t·ªï h·ª£p th·ª≠ | S·ªë l·∫ßn train (5-fold) | % t√†i nguy√™n |\n",
    "|-------------|---------------|----------------------|-------------|\n",
    "| **Grid Search** | 216 | 1,080 | 100% |\n",
    "| **Random Search** | 30 | 150 | **13.9%** |\n",
    "\n",
    "### ‚úÖ K·∫øt lu·∫≠n:\n",
    "- Random Search ch·ªâ d√πng ~14% t√†i nguy√™n!\n",
    "- Nh∆∞ng v·∫´n t√¨m ƒë∆∞·ª£c hyperparameter t·ªët!\n",
    "- **T·∫°i sao hi·ªáu qu·∫£?** V√¨ kh√¥ng ph·∫£i t·∫•t c·∫£ hyperparameters ƒë·ªÅu quan tr·ªçng nh∆∞ nhau!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c6eb6",
   "metadata": {},
   "source": [
    "---\n",
    "# B√†i 2: TPE - Thu·∫≠t to√°n \"C√≥ Tr√≠ Nh·ªõ\"\n",
    "\n",
    "## V·∫•n ƒë·ªÅ v·ªõi Random Search:\n",
    "- Random Search v·∫´n ch·ªçn ng·∫´u nhi√™n\n",
    "- Kh√¥ng \"h·ªçc\" t·ª´ c√°c l·∫ßn th·ª≠ tr∆∞·ªõc\n",
    "- C√≥ th·ªÉ l√£ng ph√≠ t√†i nguy√™n v√†o v√πng tham s·ªë x·∫•u\n",
    "\n",
    "## Gi·∫£i ph√°p: TPE (Tree-structured Parzen Estimator)\n",
    "- **H·ªçc** t·ª´ c√°c l·∫ßn th·ª≠ tr∆∞·ªõc\n",
    "- **T·∫≠p trung** v√†o v√πng tham s·ªë h·ª©a h·∫πn\n",
    "- Thu·ªôc d·∫°ng **Bayesian Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905fdd2",
   "metadata": {},
   "source": [
    "## C√†i ƒë·∫∑t Optuna\n",
    "\n",
    "Optuna l√† th∆∞ vi·ªán t·ªëi ∆∞u hyperparameter r·∫•t m·∫°nh, d√πng TPE l√†m thu·∫≠t to√°n m·∫∑c ƒë·ªãnh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a6802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N·∫øu ch∆∞a c√†i, ch·∫°y l·ªánh n√†y:\n",
    "# !pip install optuna\n",
    "\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "print(\"‚úÖ Import Optuna th√†nh c√¥ng!\")\n",
    "print(f\"üì¶ Optuna version: {optuna.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ea767",
   "metadata": {},
   "source": [
    "## ƒê·ªãnh nghƒ©a Objective Function\n",
    "\n",
    "ƒê√¢y l√† h√†m m√† Optuna s·∫Ω c·ªë g·∫Øng t·ªëi ∆∞u!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626cb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    H√†m objective cho Optuna\n",
    "    trial: ƒë·ªëi t∆∞·ª£ng ƒë·ªÉ suggest hyperparameters\n",
    "    \"\"\"\n",
    "    # Suggest hyperparameters (Optuna t·ª± ƒë·ªông ch·ªçn)\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Train model v·ªõi hyperparameters n√†y\n",
    "    model = RandomForestClassifier(**params)\n",
    "    \n",
    "    # T√≠nh accuracy b·∫±ng cross-validation\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    accuracy = scores.mean()\n",
    "    \n",
    "    return accuracy  # Return gi√° tr·ªã c·∫ßn t·ªëi ∆∞u\n",
    "\n",
    "print(\"‚úÖ ƒê·ªãnh nghƒ©a objective function xong!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4b371",
   "metadata": {},
   "source": [
    "## Ch·∫°y TPE Optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83028cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o study v·ªõi TPE sampler\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # Maximize accuracy\n",
    "    sampler=TPESampler(seed=42)  # D√πng TPE algorithm\n",
    ")\n",
    "\n",
    "# Ch·∫°y optimization v·ªõi 30 trials (gi·ªëng Random Search ƒë·ªÉ so s√°nh)\n",
    "print(\"üöÄ B·∫Øt ƒë·∫ßu TPE Optimization...\\n\")\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "print(\"\\n‚úÖ Ho√†n th√†nh!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ec722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem k·∫øt qu·∫£\n",
    "print(\"=\"*60)\n",
    "print(\"üèÜ K·∫æT QU·∫¢ TPE OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìä Best Score (CV Accuracy): {study.best_value:.4f}\")\n",
    "print(f\"\\n‚öôÔ∏è  Best Hyperparameters:\")\n",
    "for param, value in study.best_params.items():\n",
    "    print(f\"   {param:20s}: {value}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b5b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model v·ªõi best params v√† test\n",
    "best_model = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "test_score_tpe = best_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"‚ú® Test Accuracy (TPE): {test_score_tpe:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865a5ca",
   "metadata": {},
   "source": [
    "## Visualize qu√° tr√¨nh t·ªëi ∆∞u\n",
    "\n",
    "ƒê√¢y l√† ph·∫ßn th√∫ v·ªã! Ch√∫ng ta s·∫Ω xem TPE \"h·ªçc\" nh∆∞ th·∫ø n√†o!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70582aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω optimization history\n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "fig = plot_optimization_history(study)\n",
    "fig.update_layout(\n",
    "    title=\"TPE Optimization History - Titanic Dataset\",\n",
    "    xaxis_title=\"Trial Number\",\n",
    "    yaxis_title=\"Accuracy\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüìà Gi·∫£i th√≠ch:\")\n",
    "print(\"- ƒê∆∞·ªùng xanh: Accuracy c·ªßa m·ªói trial\")\n",
    "print(\"- ƒê∆∞·ªùng ƒë·ªè: Best accuracy t√¨m ƒë∆∞·ª£c cho ƒë·∫øn l√∫c ƒë√≥\")\n",
    "print(\"- Nh·∫≠n x√©t: Accuracy tƒÉng d·∫ßn ‚Üí TPE ƒëang 'h·ªçc'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642fc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω param importances\n",
    "from optuna.visualization import plot_param_importances\n",
    "\n",
    "fig = plot_param_importances(study)\n",
    "fig.update_layout(title=\"Hyperparameter Importance\")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüéØ Gi·∫£i th√≠ch:\")\n",
    "print(\"- Bi·ªÉu ƒë·ªì n√†y cho bi·∫øt hyperparameter n√†o QUAN TR·ªåNG nh·∫•t\")\n",
    "print(\"- TPE t·ª± ƒë·ªông ph√°t hi·ªán ƒëi·ªÅu n√†y!\")\n",
    "print(\"- Gi√∫p ch√∫ng ta t·∫≠p trung v√†o c√°c tham s·ªë quan tr·ªçng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4653502",
   "metadata": {},
   "source": [
    "### üß† TPE ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?\n",
    "\n",
    "**√ù t∆∞·ªüng ch√≠nh**:\n",
    "\n",
    "1. TPE chia c√°c trials th√†nh 2 nh√≥m:\n",
    "   - **Nh√≥m T·ªêT** (l): Top 20% trials c√≥ accuracy cao nh·∫•t\n",
    "   - **Nh√≥m X·∫§U** (g): 80% c√≤n l·∫°i\n",
    "\n",
    "2. TPE h·ªçc 2 ph√¢n ph·ªëi:\n",
    "   - $l(x)$: Ph√¢n ph·ªëi hyperparameters trong nh√≥m T·ªêT\n",
    "   - $g(x)$: Ph√¢n ph·ªëi hyperparameters trong nh√≥m X·∫§U\n",
    "\n",
    "3. TPE ch·ªçn $x$ m·ªõi sao cho maximize $\\frac{l(x)}{g(x)}$\n",
    "   - T·ª©c l√†: Ch·ªçn $x$ c√≥ x√°c su·∫•t **CAO** trong nh√≥m T·ªêT\n",
    "   - V√† x√°c su·∫•t **TH·∫§P** trong nh√≥m X·∫§U\n",
    "\n",
    "‚Üí ƒê√¢y ch√≠nh l√† \"tr√≠ nh·ªõ\" c·ªßa TPE! üß†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad04a0a",
   "metadata": {},
   "source": [
    "---\n",
    "# B√†i 3: So s√°nh Random Search vs TPE\n",
    "\n",
    "Gi·ªù ch√∫ng ta s·∫Ω so s√°nh tr·ª±c ti·∫øp ƒë·ªÉ th·∫•y s·ª± kh√°c bi·ªát!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363025a",
   "metadata": {},
   "source": [
    "## Ch·∫°y Random Search v·ªõi Optuna\n",
    "\n",
    "(ƒê·ªÉ c√¥ng b·∫±ng, d√πng c√πng framework Optuna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2aceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "# T·∫°o study v·ªõi Random Sampler\n",
    "study_random = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=RandomSampler(seed=42)  # D√πng Random sampling\n",
    ")\n",
    "\n",
    "print(\"üé≤ Ch·∫°y Random Search v·ªõi Optuna...\\n\")\n",
    "study_random.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "print(\"\\n‚úÖ Ho√†n th√†nh!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So s√°nh k·∫øt qu·∫£\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä SO S√ÅNH RANDOM SEARCH VS TPE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüé≤ Random Search (V√¥ nh·ªõ):\")\n",
    "print(f\"   Best Accuracy: {study_random.best_value:.4f}\")\n",
    "\n",
    "print(f\"\\nüß† TPE (C√≥ nh·ªõ):\")\n",
    "print(f\"   Best Accuracy: {study.best_value:.4f}\")\n",
    "\n",
    "if study.best_value > study_random.best_value:\n",
    "    improvement = (study.best_value - study_random.best_value) / study_random.best_value * 100\n",
    "    print(f\"\\n‚ú® TPE T·ªêT H∆†N Random Search: +{improvement:.2f}%\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  L·∫ßn n√†y Random Search may m·∫Øn h∆°n (nh∆∞ng kh√¥ng ·ªïn ƒë·ªãnh)\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a3b534",
   "metadata": {},
   "source": [
    "## So s√°nh t·ªëc ƒë·ªô h·ªôi t·ª•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c872cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y best value history\n",
    "random_history = []\n",
    "tpe_history = []\n",
    "\n",
    "random_best = 0\n",
    "for trial in study_random.trials:\n",
    "    if trial.value > random_best:\n",
    "        random_best = trial.value\n",
    "    random_history.append(random_best)\n",
    "\n",
    "tpe_best = 0\n",
    "for trial in study.trials:\n",
    "    if trial.value > tpe_best:\n",
    "        tpe_best = trial.value\n",
    "    tpe_history.append(tpe_best)\n",
    "\n",
    "# V·∫Ω bi·ªÉu ƒë·ªì\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(random_history, label='Random Search', linewidth=2.5, marker='o', markersize=5, alpha=0.7)\n",
    "plt.plot(tpe_history, label='TPE', linewidth=2.5, marker='s', markersize=5, alpha=0.7)\n",
    "plt.xlabel('Trial Number', fontsize=12)\n",
    "plt.ylabel('Best Accuracy Found', fontsize=12)\n",
    "plt.title('T·ªëc ƒë·ªô H·ªôi t·ª•: Random Search vs TPE', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Gi·∫£i th√≠ch:\")\n",
    "print(\"- Random Search: TƒÉng ch·∫≠m, dao ƒë·ªông nhi·ªÅu\")\n",
    "print(\"- TPE: TƒÉng nhanh h∆°n, ·ªïn ƒë·ªãnh h∆°n\")\n",
    "print(\"- TPE 'h·ªçc' v√† t·∫≠p trung v√†o v√πng t·ªët!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c40cc2",
   "metadata": {},
   "source": [
    "## Visualize kh√¥ng gian t√¨m ki·∫øm\n",
    "\n",
    "Xem c√°ch 2 thu·∫≠t to√°n \"explore\" kh√¥ng gian hyperparameter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3718b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y gi√° tr·ªã 2 hyperparameters quan tr·ªçng\n",
    "random_n_est = [t.params['n_estimators'] for t in study_random.trials]\n",
    "random_depth = [t.params['max_depth'] for t in study_random.trials]\n",
    "random_scores = [t.value for t in study_random.trials]\n",
    "\n",
    "tpe_n_est = [t.params['n_estimators'] for t in study.trials]\n",
    "tpe_depth = [t.params['max_depth'] for t in study.trials]\n",
    "tpe_scores = [t.value for t in study.trials]\n",
    "\n",
    "# V·∫Ω\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Random Search\n",
    "scatter1 = axes[0].scatter(random_n_est, random_depth, c=random_scores, \n",
    "                          s=150, cmap='viridis', edgecolors='black', linewidth=1.5, alpha=0.8)\n",
    "axes[0].set_xlabel('n_estimators', fontsize=12)\n",
    "axes[0].set_ylabel('max_depth', fontsize=12)\n",
    "axes[0].set_title('Random Search\\n(Th·ª≠ ng·∫´u nhi√™n)', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Accuracy')\n",
    "\n",
    "# TPE\n",
    "scatter2 = axes[1].scatter(tpe_n_est, tpe_depth, c=tpe_scores, \n",
    "                          s=150, cmap='viridis', edgecolors='black', linewidth=1.5, alpha=0.8)\n",
    "axes[1].set_xlabel('n_estimators', fontsize=12)\n",
    "axes[1].set_ylabel('max_depth', fontsize=12)\n",
    "axes[1].set_title('TPE\\n(T·∫≠p trung v√†o v√πng t·ªët)', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Accuracy')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Nh·∫≠n x√©t:\")\n",
    "print(\"- Random Search: ƒêi·ªÉm th·ª≠ ph√¢n b·ªë ƒê·ªÄU kh·∫Øp kh√¥ng gian\")\n",
    "print(\"- TPE: ƒêi·ªÉm th·ª≠ T·∫¨P TRUNG v√†o v√πng c√≥ accuracy cao (m√†u v√†ng)\")\n",
    "print(\"- TPE th√¥ng minh h∆°n trong vi·ªác s·ª≠ d·ª•ng t√†i nguy√™n!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e034de",
   "metadata": {},
   "source": [
    "---\n",
    "# üìö T·ªïng K·∫øt\n",
    "\n",
    "## üéØ B√†i 1: Curse of Dimensionality\n",
    "\n",
    "**V·∫•n ƒë·ªÅ**: \n",
    "- Grid Search ph·∫£i th·ª≠ T·∫§T C·∫¢ t·ªï h·ª£p ‚Üí S·ªë l∆∞·ª£ng tƒÉng M≈® theo s·ªë hyperparameters\n",
    "- V√≠ d·ª•: 5 params v·ªõi ~3 gi√° tr·ªã m·ªói c√°i ‚Üí ~243 t·ªï h·ª£p ‚Üí 1,215 l·∫ßn training (v·ªõi 5-fold CV)\n",
    "\n",
    "**Gi·∫£i ph√°p**:\n",
    "- Random Search ch·ªâ th·ª≠ m·ªôt PH·∫¶N ng·∫´u nhi√™n (30-50 trials)\n",
    "- Ti·∫øt ki·ªám ~85% t√†i nguy√™n nh∆∞ng v·∫´n hi·ªáu qu·∫£!\n",
    "\n",
    "---\n",
    "\n",
    "## üß† B√†i 2: TPE - \"Tr√≠ nh·ªõ\" trong t·ªëi ∆∞u\n",
    "\n",
    "**√ù t∆∞·ªüng**:\n",
    "- TPE chia trials th√†nh nh√≥m T·ªêT ($l$) v√† X·∫§U ($g$)\n",
    "- H·ªçc ph√¢n ph·ªëi hyperparameters t·ª´ 2 nh√≥m\n",
    "- Ch·ªçn hyperparameters m·ªõi ƒë·ªÉ maximize $\\frac{l(x)}{g(x)}$\n",
    "\n",
    "**∆Øu ƒëi·ªÉm**:\n",
    "- \"H·ªçc\" t·ª´ qu√° kh·ª© ‚Üí kh√¥ng l√£ng ph√≠ t√†i nguy√™n\n",
    "- T·ª± ƒë·ªông x√°c ƒë·ªãnh hyperparameters quan tr·ªçng\n",
    "- H·ªôi t·ª• nhanh h∆°n Random Search\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è B√†i 3: So s√°nh\n",
    "\n",
    "| Ph∆∞∆°ng ph√°p | Chi·∫øn l∆∞·ª£c | ∆Øu ƒëi·ªÉm | Nh∆∞·ª£c ƒëi·ªÉm |\n",
    "|-------------|-----------|---------|------------|\n",
    "| **Grid Search** | Th·ª≠ t·∫•t c·∫£ | ƒê·∫ßy ƒë·ªß | C·ª±c k·ª≥ ch·∫≠m |\n",
    "| **Random Search** | Th·ª≠ ng·∫´u nhi√™n | Nhanh, ƒë∆°n gi·∫£n | Kh√¥ng h·ªçc t·ª´ qu√° kh·ª© |\n",
    "| **TPE** | H·ªçc & t·∫≠p trung | Nhanh + Th√¥ng minh | C·∫ßn setup ph·ª©c t·∫°p h∆°n |\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Khuy·∫øn ngh·ªã th·ª±c t·∫ø:\n",
    "\n",
    "1. **Kh√¥ng gian nh·ªè** (< 50 t·ªï h·ª£p): D√πng **Grid Search**\n",
    "2. **Kh√¥ng gian v·ª´a, c·∫ßn nhanh**: D√πng **Random Search**\n",
    "3. **Kh√¥ng gian l·ªõn, mu·ªën t·ªët nh·∫•t**: D√πng **TPE/Optuna** ‚≠ê\n",
    "4. **Production**: Lu√¥n d√πng TPE/Bayesian Optimization!\n",
    "\n",
    "---\n",
    "\n",
    "## üéì B√†i h·ªçc quan tr·ªçng:\n",
    "\n",
    "1. **Kh√¥ng ph·∫£i hyperparameter n√†o c≈©ng quan tr·ªçng nh∆∞ nhau**\n",
    "   ‚Üí Random Search hi·ªáu qu·∫£ v√¨ t·∫≠p trung v√†o chi·ªÅu quan tr·ªçng\n",
    "\n",
    "2. **\"Memory\" (tr√≠ nh·ªõ) r·∫•t quan tr·ªçng**\n",
    "   ‚Üí TPE h·ªçc t·ª´ qu√° kh·ª© ƒë·ªÉ t·ªëi ∆∞u t∆∞∆°ng lai\n",
    "\n",
    "3. **Trade-off gi·ªØa exploration v√† exploitation**\n",
    "   - Grid/Random: Exploration nhi·ªÅu\n",
    "   - TPE: Balance t·ªët gi·ªØa explore (th·ª≠ v√πng m·ªõi) v√† exploit (khai th√°c v√πng t·ªët)\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Th·ª±c h√†nh th√™m:\n",
    "\n",
    "- Th·ª≠ v·ªõi dataset kh√°c (housing prices, iris, etc.)\n",
    "- Th·ª≠ v·ªõi model kh√°c (SVM, XGBoost, Neural Networks)\n",
    "- Th·ª≠ nhi·ªÅu trials h∆°n (100, 200) ƒë·ªÉ th·∫•y s·ª± kh√°c bi·ªát r√µ h∆°n\n",
    "- T√¨m hi·ªÉu v·ªÅ c√°c sampler kh√°c: CmaEsSampler, NSGAIISampler (multi-objective)\n",
    "\n",
    "**Ch√∫c b·∫°n h·ªçc t·ªët! üéâ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
